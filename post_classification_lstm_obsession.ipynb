{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbd38007-95a6-4e7c-98ac-20e48444dc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score,classification_report, confusion_matrix,precision_score, recall_score\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da6c99b2-dcd8-4fbd-a24f-4fcb4efc8d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>prefLabel</th>\n",
       "      <th>obsession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi -\\nSo I haven't been on here since December...</td>\n",
       "      <td>['depression', 'weight gain', 'Medication', 'a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi all, hope you're all having a wonderful ban...</td>\n",
       "      <td>['compulsion', 'anger', 'symptom', 'compassion...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi, \\nFirst, I hope everyone managed to have s...</td>\n",
       "      <td>['hope', 'happiness', 'guilt', 'fear', 'obsess...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello everyone. I could really use your help r...</td>\n",
       "      <td>['Treatment', 'hope', 'Thought', 'obsession', ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Though it comes in many flavors, one of the mo...</td>\n",
       "      <td>['quality', 'Intrusive thoughts', 'fall', 'beh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  \\\n",
       "0  Hi -\\nSo I haven't been on here since December...   \n",
       "1  Hi all, hope you're all having a wonderful ban...   \n",
       "2  Hi, \\nFirst, I hope everyone managed to have s...   \n",
       "3  Hello everyone. I could really use your help r...   \n",
       "4  Though it comes in many flavors, one of the mo...   \n",
       "\n",
       "                                           prefLabel  obsession  \n",
       "0  ['depression', 'weight gain', 'Medication', 'a...          1  \n",
       "1  ['compulsion', 'anger', 'symptom', 'compassion...          1  \n",
       "2  ['hope', 'happiness', 'guilt', 'fear', 'obsess...          1  \n",
       "3  ['Treatment', 'hope', 'Thought', 'obsession', ...          1  \n",
       "4  ['quality', 'Intrusive thoughts', 'fall', 'beh...          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#post data\n",
    "df = pd.read_csv('processed_data/labled_data.csv',usecols=['post', 'prefLabel','obsession'])\n",
    "df1 = pd.read_csv('input_data/Post_ModelPredictions_ManualChecking.csv', usecols=['post', 'prefLabel'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0136dc6d-2436-4f31-afd2-f08293230e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['obsession'] = [0] * len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e04e72f5-74f9-4599-9bd6-26715af62ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2953"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_emptyLabel = df1[df1['prefLabel'] == '[]']\n",
    "len(df1_emptyLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61d2c39a-9edf-47db-8684-532a9af485e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.concat([df, df1_emptyLabel], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c015b2e-afd6-49dc-a76c-efe198bf727b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9497, 4985)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df2), df2['obsession'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba13dbc9-b76e-48f1-b9c7-cac95be48082",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2131dc-43bc-4cf7-bda4-4f320ff853ce",
   "metadata": {},
   "source": [
    "# **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76b6b8fe-8864-47ec-873a-3475e6bb629c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print the number of post in each ensemble for each class(test data)\n",
    "LABEL_COLUMNS = df.columns.tolist()[2:]\n",
    "df[LABEL_COLUMNS].sum().sort_values().plot(kind=\"barh\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "895c3d61-5913-476d-b3b4-be7daaf63f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#define the process of text cleaning\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r' ',text)\n",
    "#Clean Text\n",
    "def clean_text(data):\n",
    "    # convert catacter to lowercase\n",
    "    data['clean_text']=data['post'].str.lower()\n",
    "    #remove URLS\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"http\\S+\", \"\", elem))\n",
    "    #remove ponctuation\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"[^\\w\\s]\", \"\", elem))\n",
    "    #remove\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'/n',\"\",elem))\n",
    "    #remove degits\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\d+',\"\",elem))\n",
    "    #remove emojis\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:deEmojify(elem))\n",
    "    #remove multiple spaces\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+',\" \",elem))\n",
    "    #remove single caracter\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+[a-zA-Z]\\s+',\" \",elem))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8645f99d-bef1-4d6d-b52b-dcfa40682ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the process of cleaning for the train and test data\n",
    "df = clean_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff3e93de-e037-4194-be38-e690ed065f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#for the text pre-processing (text cleaning)\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import re #regular expression\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize # word tokenization\n",
    "from nltk.stem import PorterStemmer # word stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e9f9198-c262-4c69-b8e4-6b6ad9804e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19ca0593-b7b8-401a-ab39-f598e9c6672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "  stopW=stopwords.words('english')\n",
    "  s=\"\"\n",
    "  for i in text.split():\n",
    "    if i not in stopW:\n",
    "        s=s+i+\" \"\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee1b675d-6a72-4116-a540-a9d4dfef4dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text']=df['clean_text'].apply(lambda x:remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5505f151-fe9c-4b17-87bc-7306e5ff0ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(ch):\n",
    "  stem = PorterStemmer()\n",
    "  return \" \".join([stem.stem(i) for i in ch.split()])\n",
    "\n",
    "#apply the stem function to each row in the dataframe\n",
    "df['clean_text'] = df['clean_text'].apply(lambda x:stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61f0a3fe-cae5-40c6-8894-51ba183d7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = df['clean_text'], df[['obsession']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e37f2988-99f3-4d8d-9d47-b843a1a0f4c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7597,), (7597, 1), (1900,), (1900, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23574a4f-04e0-4ad5-8842-3e058c5cbf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22360\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "num_words = 2000\n",
    "vect=Tokenizer(num_words=num_words)\n",
    "vect.fit_on_texts(X_train)\n",
    "vocab_size = len(vect.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a547b0bd-e654-4d23-b08e-92641d152595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7597, 150)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoded_docs_train = vect.texts_to_sequences(X_train)\n",
    "MAX_LEN = 150\n",
    "padded_docs_train = pad_sequences(encoded_docs_train, maxlen=MAX_LEN, padding='pre')\n",
    "padded_docs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d80128e-5e79-472d-8940-1c986d0e7204",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs_test =  vect.texts_to_sequences(X_test)\n",
    "padded_docs_test = pad_sequences(encoded_docs_test, maxlen=MAX_LEN, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02bb9c57-8842-419c-8c42-f01fa29dd881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e876a43-6f81-4a8e-ae73-a4466cb9c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    # Configuring the parameters\n",
    "    model.add(Embedding(num_words, output_dim=16, input_length=MAX_LEN))\n",
    "    model.add(LSTM(16, return_sequences=True))  \n",
    "    # Adding a dropout layer\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(LSTM(8))\n",
    "    # model.add(Dropout(0.5))\n",
    "    model.add(Dense(4))\n",
    "    # model.add(Dropout(0.5))\n",
    "    # Adding a dense output layer with sigmoid activation\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca5ec77b-f57b-46c3-8641-7aec733b013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 150, 16)           32000     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 150, 16)           2112      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 150, 16)           0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 8)                 800       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 36        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,953\n",
      "Trainable params: 34,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1000\n",
      "380/380 [==============================] - 23s 54ms/step - loss: 0.4471 - acc: 0.8042 - val_loss: 0.3530 - val_acc: 0.8770 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.2627 - acc: 0.9157 - val_loss: 0.2720 - val_acc: 0.9092 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.2323 - acc: 0.9294 - val_loss: 0.2692 - val_acc: 0.9125 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.2187 - acc: 0.9335 - val_loss: 0.2695 - val_acc: 0.9151 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "380/380 [==============================] - 21s 56ms/step - loss: 0.2163 - acc: 0.9329 - val_loss: 0.2637 - val_acc: 0.9099 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.1853 - acc: 0.9437 - val_loss: 0.2668 - val_acc: 0.9000 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.1891 - acc: 0.9340 - val_loss: 0.2656 - val_acc: 0.9066 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "380/380 [==============================] - 21s 56ms/step - loss: 0.1709 - acc: 0.9455 - val_loss: 0.2506 - val_acc: 0.9033 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.1487 - acc: 0.9552 - val_loss: 0.2791 - val_acc: 0.9026 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.1350 - acc: 0.9590 - val_loss: 0.2727 - val_acc: 0.9059 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.1221 - acc: 0.9640 - val_loss: 0.2877 - val_acc: 0.9092 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.1078 - acc: 0.9705 - val_loss: 0.3576 - val_acc: 0.9039 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.0944 - acc: 0.9748 - val_loss: 0.3520 - val_acc: 0.9053 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.0880 - acc: 0.9771 - val_loss: 0.3748 - val_acc: 0.9000 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.1189 - acc: 0.9666 - val_loss: 0.3906 - val_acc: 0.9053 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.1368 - acc: 0.9623 - val_loss: 0.4400 - val_acc: 0.8868 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.1439 - acc: 0.9569 - val_loss: 0.3108 - val_acc: 0.8901 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.1988 - acc: 0.9320 - val_loss: 0.2573 - val_acc: 0.9145 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "380/380 [==============================] - 20s 54ms/step - loss: 0.1296 - acc: 0.9564 - val_loss: 0.2711 - val_acc: 0.9066 - lr: 2.0000e-04\n",
      "Epoch 20/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.0939 - acc: 0.9712 - val_loss: 0.3528 - val_acc: 0.8987 - lr: 2.0000e-04\n",
      "Epoch 27/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.0865 - acc: 0.9728 - val_loss: 0.3339 - val_acc: 0.9026 - lr: 2.0000e-04\n",
      "Epoch 28/1000\n",
      "380/380 [==============================] - 21s 55ms/step - loss: 0.0851 - acc: 0.9735 - val_loss: 0.3609 - val_acc: 0.8980 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "obsession_model = get_model()\n",
    "obsession_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = obsession_model.fit(padded_docs_train, y_train, epochs=1000, batch_size=16,validation_split=0.2,\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',patience=20, min_delta=1e-7),\n",
    "                              keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=10),\n",
    "                              keras.callbacks.ModelCheckpoint(filepath='model/lstm_obsession_model.h5', \n",
    "                                      monitor='val_loss', \n",
    "                                      save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e24579e-0248-49a7-b7d3-4d00898f8d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "obsession_model.load_weights('model/lstm_obsession_model.h5')\n",
    "obsession_predictions = obsession_model.predict([padded_docs_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33b7a3c0-3e0e-47cd-b31b-c175a6787b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obsession Prediction Result\n",
      "Micro-average quality numbers for threshold 0.1\n",
      "Precision: 0.8595, Recall: 0.8595, F1-measure: 0.8595\n",
      "Micro-average quality numbers for threshold 0.2\n",
      "Precision: 0.8784, Recall: 0.8784, F1-measure: 0.8784\n",
      "Micro-average quality numbers for threshold 0.3\n",
      "Precision: 0.8889, Recall: 0.8889, F1-measure: 0.8889\n",
      "Micro-average quality numbers for threshold 0.4\n",
      "Precision: 0.8947, Recall: 0.8947, F1-measure: 0.8947\n",
      "Micro-average quality numbers for threshold 0.5\n",
      "Precision: 0.8984, Recall: 0.8984, F1-measure: 0.8984\n",
      "Micro-average quality numbers for threshold 0.6\n",
      "Precision: 0.9011, Recall: 0.9011, F1-measure: 0.9011\n",
      "Micro-average quality numbers for threshold 0.7\n",
      "Precision: 0.9026, Recall: 0.9026, F1-measure: 0.9026\n",
      "Micro-average quality numbers for threshold 0.8\n",
      "Precision: 0.8968, Recall: 0.8968, F1-measure: 0.8968\n",
      "Micro-average quality numbers for threshold 0.9\n",
      "Precision: 0.8800, Recall: 0.8800, F1-measure: 0.8800\n"
     ]
    }
   ],
   "source": [
    "print('Obsession Prediction Result')\n",
    "thresholds=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for val in thresholds:\n",
    "    pred=obsession_predictions.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "  \n",
    "    precision = precision_score(y_test.values, pred, average='micro')\n",
    "    recall = recall_score(y_test.values, pred, average='micro')\n",
    "    f1 = f1_score(y_test.values, pred, average='micro')\n",
    "   \n",
    "    print(\"Micro-average quality numbers for threshold\", val)\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d59d73d-de9b-4181-a9f5-206bc59b9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = y_test.copy()\n",
    "Y_test['obsession_pred'] = obsession_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba3d3baa-d557-4b5d-82cb-a2d8cf59c915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obsession</th>\n",
       "      <th>obsession_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>0</td>\n",
       "      <td>0.230116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>1</td>\n",
       "      <td>0.964446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>0</td>\n",
       "      <td>0.076932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3812</th>\n",
       "      <td>1</td>\n",
       "      <td>0.909074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6098</th>\n",
       "      <td>1</td>\n",
       "      <td>0.931195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3884</th>\n",
       "      <td>1</td>\n",
       "      <td>0.964568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4907</th>\n",
       "      <td>0</td>\n",
       "      <td>0.104986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23560</th>\n",
       "      <td>0</td>\n",
       "      <td>0.014247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409</th>\n",
       "      <td>0</td>\n",
       "      <td>0.091485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21393</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>1</td>\n",
       "      <td>0.929146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>0</td>\n",
       "      <td>0.512384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>1</td>\n",
       "      <td>0.959623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655</th>\n",
       "      <td>1</td>\n",
       "      <td>0.965089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>1</td>\n",
       "      <td>0.965695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2043</th>\n",
       "      <td>1</td>\n",
       "      <td>0.963082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4209</th>\n",
       "      <td>0</td>\n",
       "      <td>0.229594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>1</td>\n",
       "      <td>0.962362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5591</th>\n",
       "      <td>1</td>\n",
       "      <td>0.965222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20185</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5982</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>1</td>\n",
       "      <td>0.962466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4053</th>\n",
       "      <td>1</td>\n",
       "      <td>0.918907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8985</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8913</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3010</th>\n",
       "      <td>1</td>\n",
       "      <td>0.964756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>1</td>\n",
       "      <td>0.839279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10147</th>\n",
       "      <td>0</td>\n",
       "      <td>0.003460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7314</th>\n",
       "      <td>0</td>\n",
       "      <td>0.028949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>0</td>\n",
       "      <td>0.008992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23612</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>1</td>\n",
       "      <td>0.964138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>0</td>\n",
       "      <td>0.355627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22025</th>\n",
       "      <td>0</td>\n",
       "      <td>0.004426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1</td>\n",
       "      <td>0.966805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       obsession  obsession_pred\n",
       "1593           0        0.230116\n",
       "4313           0        0.005576\n",
       "2059           1        0.964446\n",
       "4959           0        0.009660\n",
       "5299           0        0.076932\n",
       "4633           0        0.004332\n",
       "3812           1        0.909074\n",
       "6098           1        0.931195\n",
       "3884           1        0.964568\n",
       "2406           0        0.003659\n",
       "4907           0        0.104986\n",
       "23560          0        0.014247\n",
       "5409           0        0.091485\n",
       "21393          0        0.009790\n",
       "5111           1        0.929146\n",
       "2740           0        0.512384\n",
       "3234           1        0.959623\n",
       "3655           1        0.965089\n",
       "1978           1        0.965695\n",
       "2043           1        0.963082\n",
       "4209           0        0.229594\n",
       "5306           1        0.962362\n",
       "5591           1        0.965222\n",
       "20185          0        0.004337\n",
       "5982           1        0.366207\n",
       "2703           1        0.962466\n",
       "4053           1        0.918907\n",
       "2785           0        0.004151\n",
       "8985           0        0.006273\n",
       "8913           0        0.004430\n",
       "3010           1        0.964756\n",
       "2176           1        0.839279\n",
       "10147          0        0.003460\n",
       "7314           0        0.028949\n",
       "1607           0        0.008992\n",
       "23612          0        0.004159\n",
       "5559           1        0.964138\n",
       "4674           0        0.355627\n",
       "22025          0        0.004426\n",
       "296            1        0.966805"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86173202-4933-41ce-a597-01dd4da47d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model/lstm_tockenizer_obsession.pkl', 'wb') as f:\n",
    "    pickle.dump(vect, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf4c90-3106-40ab-b650-40827d8e02a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
