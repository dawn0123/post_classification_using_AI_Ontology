{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbd38007-95a6-4e7c-98ac-20e48444dc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score,classification_report, confusion_matrix,precision_score, recall_score\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da6c99b2-dcd8-4fbd-a24f-4fcb4efc8d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>compulsion</th>\n",
       "      <th>obs-com</th>\n",
       "      <th>obsession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi -\\nSo I haven't been on here since December...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi all, hope you're all having a wonderful ban...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi, \\nFirst, I hope everyone managed to have s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello everyone. I could really use your help r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Though it comes in many flavors, one of the mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  compulsion  obs-com  \\\n",
       "0  Hi -\\nSo I haven't been on here since December...           0        0   \n",
       "1  Hi all, hope you're all having a wonderful ban...           1        1   \n",
       "2  Hi, \\nFirst, I hope everyone managed to have s...           0        0   \n",
       "3  Hello everyone. I could really use your help r...           0        0   \n",
       "4  Though it comes in many flavors, one of the mo...           1        1   \n",
       "\n",
       "   obsession  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#post data\n",
    "df = pd.read_csv('processed_data/labled_data.csv',usecols=['post','compulsion','obs-com','obsession'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2131dc-43bc-4cf7-bda4-4f320ff853ce",
   "metadata": {},
   "source": [
    "# **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76b6b8fe-8864-47ec-873a-3475e6bb629c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print the number of post in each ensemble for each class(test data)\n",
    "LABEL_COLUMNS = df.columns.tolist()[1:]\n",
    "df[LABEL_COLUMNS].sum().sort_values().plot(kind=\"barh\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "895c3d61-5913-476d-b3b4-be7daaf63f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#define the process of text cleaning\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r' ',text)\n",
    "#Clean Text\n",
    "def clean_text(data):\n",
    "    # convert catacter to lowercase\n",
    "    data['clean_text']=data['post'].str.lower()\n",
    "    #remove URLS\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"http\\S+\", \"\", elem))\n",
    "    #remove ponctuation\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"[^\\w\\s]\", \"\", elem))\n",
    "    #remove\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'/n',\"\",elem))\n",
    "    #remove degits\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\d+',\"\",elem))\n",
    "    #remove emojis\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:deEmojify(elem))\n",
    "    #remove multiple spaces\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+',\" \",elem))\n",
    "    #remove single caracter\n",
    "    data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+[a-zA-Z]\\s+',\" \",elem))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8645f99d-bef1-4d6d-b52b-dcfa40682ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the process of cleaning for the train and test data\n",
    "df = clean_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff3e93de-e037-4194-be38-e690ed065f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#for the text pre-processing (text cleaning)\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import re #regular expression\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize # word tokenization\n",
    "from nltk.stem import PorterStemmer # word stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e9f9198-c262-4c69-b8e4-6b6ad9804e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19ca0593-b7b8-401a-ab39-f598e9c6672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "  stopW=stopwords.words('english')\n",
    "  s=\"\"\n",
    "  for i in text.split():\n",
    "    if i not in stopW:\n",
    "        s=s+i+\" \"\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee1b675d-6a72-4116-a540-a9d4dfef4dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text']=df['clean_text'].apply(lambda x:remove_stop_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5505f151-fe9c-4b17-87bc-7306e5ff0ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(ch):\n",
    "  stem = PorterStemmer()\n",
    "  return \" \".join([stem.stem(i) for i in ch.split()])\n",
    "\n",
    "#apply the stem function to each row in the dataframe\n",
    "df['clean_text'] = df['clean_text'].apply(lambda x:stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61f0a3fe-cae5-40c6-8894-51ba183d7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = df['clean_text'], df[['compulsion','obsession']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7437eb2-d2d6-488c-a746-ae8a7c7c1640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5235,), (5235, 2), (1309,), (1309, 2))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23574a4f-04e0-4ad5-8842-3e058c5cbf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20555\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "vect=Tokenizer()\n",
    "vect.fit_on_texts(X_train)\n",
    "vocab_size = len(vect.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a547b0bd-e654-4d23-b08e-92641d152595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  25  608  192 ...  266  515  151]\n",
      " [  70  144  299 ...    0    0    0]\n",
      " [  88  251  183 ...    0    0    0]\n",
      " ...\n",
      " [  92  997   23 ...    0    0    0]\n",
      " [  63 1132 1684 ... 3962   66 4223]\n",
      " [   3    6  144 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "encoded_docs_train = vect.texts_to_sequences(X_train)\n",
    "MAX_LEN = 100\n",
    "padded_docs_train = pad_sequences(encoded_docs_train, maxlen=MAX_LEN, padding='post')\n",
    "print(padded_docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d80128e-5e79-472d-8940-1c986d0e7204",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs_test =  vect.texts_to_sequences(X_test)\n",
    "padded_docs_test = pad_sequences(encoded_docs_test, maxlen=MAX_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02bb9c57-8842-419c-8c42-f01fa29dd881",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e876a43-6f81-4a8e-ae73-a4466cb9c154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 8)            164440    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100, 8)            544       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 8)            0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 8)                 544       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165,546\n",
      "Trainable params: 165,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# Configuring the parameters\n",
    "model.add(Embedding(vocab_size, output_dim=8, input_length=MAX_LEN))\n",
    "model.add(LSTM(8, return_sequences=True))  \n",
    "# Adding a dropout layer\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(8))\n",
    "model.add(Dropout(0.5))\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca5ec77b-f57b-46c3-8641-7aec733b013e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "262/262 [==============================] - 12s 37ms/step - loss: 0.6352 - acc: 0.6089 - val_loss: 0.6116 - val_acc: 0.5998 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.6070 - acc: 0.6082 - val_loss: 0.6203 - val_acc: 0.5998 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "262/262 [==============================] - 10s 38ms/step - loss: 0.5113 - acc: 0.6917 - val_loss: 0.4751 - val_acc: 0.7545 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "262/262 [==============================] - 9s 36ms/step - loss: 0.3953 - acc: 0.8312 - val_loss: 0.4442 - val_acc: 0.7765 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.3189 - acc: 0.8799 - val_loss: 0.4554 - val_acc: 0.7851 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "262/262 [==============================] - 9s 36ms/step - loss: 0.2745 - acc: 0.9047 - val_loss: 0.4050 - val_acc: 0.7985 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.2483 - acc: 0.9088 - val_loss: 0.4172 - val_acc: 0.8176 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "262/262 [==============================] - 9s 36ms/step - loss: 0.2240 - acc: 0.9186 - val_loss: 0.4011 - val_acc: 0.7947 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.2065 - acc: 0.9224 - val_loss: 0.4940 - val_acc: 0.8252 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.1931 - acc: 0.9279 - val_loss: 0.4197 - val_acc: 0.8071 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.1713 - acc: 0.9288 - val_loss: 0.5161 - val_acc: 0.7918 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.1738 - acc: 0.9272 - val_loss: 0.5105 - val_acc: 0.8138 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.1581 - acc: 0.9305 - val_loss: 0.4846 - val_acc: 0.8204 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.1428 - acc: 0.9360 - val_loss: 0.4972 - val_acc: 0.8138 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.1296 - acc: 0.9322 - val_loss: 0.5895 - val_acc: 0.8300 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.1219 - acc: 0.9374 - val_loss: 0.5286 - val_acc: 0.8185 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.1160 - acc: 0.9334 - val_loss: 0.5368 - val_acc: 0.8300 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "262/262 [==============================] - 9s 36ms/step - loss: 0.1173 - acc: 0.9348 - val_loss: 0.6022 - val_acc: 0.8204 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.0978 - acc: 0.9329 - val_loss: 0.5521 - val_acc: 0.8233 - lr: 2.0000e-04\n",
      "Epoch 20/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.0906 - acc: 0.9343 - val_loss: 0.5586 - val_acc: 0.8233 - lr: 2.0000e-04\n",
      "Epoch 21/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.0842 - acc: 0.9348 - val_loss: 0.5705 - val_acc: 0.8243 - lr: 2.0000e-04\n",
      "Epoch 22/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.0898 - acc: 0.9322 - val_loss: 0.5748 - val_acc: 0.8233 - lr: 2.0000e-04\n",
      "Epoch 23/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.0854 - acc: 0.9386 - val_loss: 0.5978 - val_acc: 0.8185 - lr: 2.0000e-04\n",
      "Epoch 24/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.0847 - acc: 0.9365 - val_loss: 0.6115 - val_acc: 0.8204 - lr: 2.0000e-04\n",
      "Epoch 25/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.0768 - acc: 0.9429 - val_loss: 0.6195 - val_acc: 0.8090 - lr: 2.0000e-04\n",
      "Epoch 26/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.0777 - acc: 0.9408 - val_loss: 0.6316 - val_acc: 0.8204 - lr: 2.0000e-04\n",
      "Epoch 27/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.0776 - acc: 0.9417 - val_loss: 0.6289 - val_acc: 0.8138 - lr: 2.0000e-04\n",
      "Epoch 28/1000\n",
      "262/262 [==============================] - 9s 35ms/step - loss: 0.0759 - acc: 0.9379 - val_loss: 0.6326 - val_acc: 0.8109 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(padded_docs_train, y_train, epochs=1000, batch_size=16,validation_split=0.2,\n",
    "                    callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',patience=20, min_delta=1e-7),\n",
    "                              keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=10),\n",
    "                              keras.callbacks.ModelCheckpoint(filepath='model/lstm_model.h5', \n",
    "                                      monitor='val_loss', \n",
    "                                      save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34d9915a-2d6c-4c0c-8811-13fadc27bddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 6ms/step\n",
      "Micro-average quality numbers for threshold 0.1\n",
      "Precision: 0.8098, Recall: 0.9147, F1-measure: 0.8591\n",
      "Micro-average quality numbers for threshold 0.2\n",
      "Precision: 0.8183, Recall: 0.9048, F1-measure: 0.8594\n",
      "Micro-average quality numbers for threshold 0.3\n",
      "Precision: 0.8205, Recall: 0.9002, F1-measure: 0.8585\n",
      "Micro-average quality numbers for threshold 0.4\n",
      "Precision: 0.8213, Recall: 0.8962, F1-measure: 0.8571\n",
      "Micro-average quality numbers for threshold 0.5\n",
      "Precision: 0.8225, Recall: 0.8942, F1-measure: 0.8569\n",
      "Micro-average quality numbers for threshold 0.6\n",
      "Precision: 0.8241, Recall: 0.8890, F1-measure: 0.8553\n",
      "Micro-average quality numbers for threshold 0.7\n",
      "Precision: 0.8280, Recall: 0.8876, F1-measure: 0.8568\n",
      "Micro-average quality numbers for threshold 0.8\n",
      "Precision: 0.8330, Recall: 0.8804, F1-measure: 0.8560\n",
      "Micro-average quality numbers for threshold 0.9\n",
      "Precision: 0.8443, Recall: 0.8566, F1-measure: 0.8504\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict([padded_docs_test])\n",
    "thresholds=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "for val in thresholds:\n",
    "    pred=predictions.copy()\n",
    "  \n",
    "    pred[pred>=val]=1\n",
    "    pred[pred<val]=0\n",
    "  \n",
    "    precision = precision_score(y_test, pred, average='micro')\n",
    "    recall = recall_score(y_test, pred, average='micro')\n",
    "    f1 = f1_score(y_test, pred, average='micro')\n",
    "   \n",
    "    print(\"Micro-average quality numbers for threshold\", val)\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33b7a3c0-3e0e-47cd-b31b-c175a6787b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      compulsion  obsession\n",
       " 1277           1          1\n",
       " 4982           1          1\n",
       " 1022           0          1\n",
       " 5835           0          1\n",
       " 1675           0          1\n",
       " 2137           1          0\n",
       " 48             1          1\n",
       " 751            0          1\n",
       " 1106           1          0\n",
       " 3680           1          0,\n",
       " array([[0.995558  , 0.29322684],\n",
       "        [0.00270869, 0.9995541 ],\n",
       "        [0.0019342 , 0.9996596 ],\n",
       "        [0.0018913 , 0.99966586],\n",
       "        [0.97111917, 0.95039743],\n",
       "        [0.9979401 , 0.04635631],\n",
       "        [0.92226934, 0.97536045],\n",
       "        [0.00189215, 0.99966574],\n",
       "        [0.00195244, 0.9996566 ],\n",
       "        [0.9982056 , 0.03724323]], dtype=float32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10], predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d59d73d-de9b-4181-a9f5-206bc59b9a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = y_test.copy()\n",
    "Y_test['compulsion_pred'] = predictions[:, 0]\n",
    "Y_test['obsession_pred'] = predictions[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba3d3baa-d557-4b5d-82cb-a2d8cf59c915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compulsion</th>\n",
       "      <th>obsession</th>\n",
       "      <th>compulsion_pred</th>\n",
       "      <th>obsession_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995558</td>\n",
       "      <td>0.293227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.999554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.999660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5835</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.999666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.971119</td>\n",
       "      <td>0.950397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.997940</td>\n",
       "      <td>0.046356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.922269</td>\n",
       "      <td>0.975360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.999666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.999657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3680</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998206</td>\n",
       "      <td>0.037243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.999598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.999650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.999666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.999598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.999468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.999527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.999664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.998216</td>\n",
       "      <td>0.036699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.999648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6460</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>0.999120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      compulsion  obsession  compulsion_pred  obsession_pred\n",
       "1277           1          1         0.995558        0.293227\n",
       "4982           1          1         0.002709        0.999554\n",
       "1022           0          1         0.001934        0.999660\n",
       "5835           0          1         0.001891        0.999666\n",
       "1675           0          1         0.971119        0.950397\n",
       "2137           1          0         0.997940        0.046356\n",
       "48             1          1         0.922269        0.975360\n",
       "751            0          1         0.001892        0.999666\n",
       "1106           1          0         0.001952        0.999657\n",
       "3680           1          0         0.998206        0.037243\n",
       "2829           0          1         0.002342        0.999598\n",
       "683            1          0         0.002051        0.999650\n",
       "3389           0          1         0.001891        0.999666\n",
       "3993           0          1         0.002360        0.999598\n",
       "1284           1          1         0.003253        0.999468\n",
       "2026           0          1         0.002872        0.999527\n",
       "1460           0          1         0.001906        0.999664\n",
       "2979           1          0         0.998216        0.036699\n",
       "263            0          1         0.002013        0.999648\n",
       "6460           0          1         0.007410        0.999120"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e40c9a6d-5a09-49d1-9047-6c6d039abf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86173202-4933-41ce-a597-01dd4da47d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model/lstm_tockenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vect, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf4c90-3106-40ab-b650-40827d8e02a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
